[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Note\n\n\n\nMost of my notes of studying this chapter is done in ‘r-tidyverse.ipynb’ (see workspace content). Just in case it is necessary to show it."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#libraries",
    "href": "content/01_journal/01_tidyverse.html#libraries",
    "title": "Tidyverse",
    "section": "1.1 Libraries",
    "text": "1.1 Libraries\n\nlibrary(readxl)\nlibrary(lubridate)\n\n#&gt; \n#&gt; Attache Paket: 'lubridate'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:base':\n#&gt; \n#&gt;     date, intersect, setdiff, union\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n#&gt; ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n#&gt; ✔ tibble  3.1.6     ✔ dplyr   1.0.8\n#&gt; ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#&gt; ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ lubridate::as.difftime() masks base::as.difftime()\n#&gt; ✖ lubridate::date()        masks base::date()\n#&gt; ✖ dplyr::filter()          masks stats::filter()\n#&gt; ✖ lubridate::intersect()   masks base::intersect()\n#&gt; ✖ dplyr::lag()             masks stats::lag()\n#&gt; ✖ lubridate::setdiff()     masks base::setdiff()\n#&gt; ✖ lubridate::union()       masks base::union()\n\nlibrary(readr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#data-imports",
    "href": "content/01_journal/01_tidyverse.html#data-imports",
    "title": "Tidyverse",
    "section": "1.2 Data imports",
    "text": "1.2 Data imports\n\nbikes_tbl = read_excel(\"ds_data/ds_data/01_bike_sales/01_raw_data/bikes.xlsx\")\norderlines_tbl = read_excel(\"ds_data/ds_data/01_bike_sales/01_raw_data/orderlines.xlsx\")\n\n#&gt; New names:\n#&gt; • `` -&gt; `...1`\n\nbikeshops_tbl = read_excel(\"ds_data/ds_data/01_bike_sales/01_raw_data/bikeshops.xlsx\")"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#examine",
    "href": "content/01_journal/01_tidyverse.html#examine",
    "title": "Tidyverse",
    "section": "1.3 Examine",
    "text": "1.3 Examine\n\nhead(bikes_tbl, n=5)\n\n\n\n  \n\n\nhead(orderlines_tbl, n=5)\n\n\n\n  \n\n\nhead(bikeshops_tbl, n=5)"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#data-manipulation-and-cleaning",
    "href": "content/01_journal/01_tidyverse.html#data-manipulation-and-cleaning",
    "title": "Tidyverse",
    "section": "1.4 Data Manipulation and cleaning",
    "text": "1.4 Data Manipulation and cleaning\n\nproduct.id from orderlines.xlsx are the same as bike.id from bikes.xlsx\nTherefore they are combined (both dataset share product.id)\nCombining customer.id from orderlines.xlsx and bikeshop.id from bikeshops.xlsx\nBecause the bikeshops (middle man) are buying and selling to customers, therefore they are the customer of the supplier (Seller)\n\n\ndplyr::left_join(orderlines_tbl, bikes_tbl, by = c(\"product.id\" = \"bike.id\"))\n\n\n\n  \n\n\n\n\nbike_orderlines_joined_tbl = orderlines_tbl %&gt;%\n    dplyr::left_join(bikes_tbl, by = c(\"product.id\" = \"bike.id\")) %&gt;% \n    dplyr::left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\n\nhead(bike_orderlines_joined_tbl, n = 5)\n\n\n\n  \n\n\n\n\nbike_orderlines_wrangled_tbl = bike_orderlines_joined_tbl %&gt;%\n    separate(col = category,\n            into = c(\"category.1\", \"category.2\", \"category.3\"),\n            sep = \" - \") %&gt;%\n    mutate(total.price = price * quantity) %&gt;%\n    dplyr::select(-...1, -gender) %&gt;%\n    dplyr::select(-ends_with(\".id\")) %&gt;%\n    bind_cols(bike_orderlines_joined_tbl %&gt;% dplyr::select(order.id)) %&gt;%\n    dplyr::select(order.id, contains(\"order\"), contains(\"model\"), contains(\"category\"),\n          price, quantity, total.price, everything()) %&gt;%\n    rename(bikeshop = name) %&gt;%\n    set_names(names(.) %&gt;% str_replace_all(\"\\\\.\", \"_\"))"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#analyse-sales-by-state-with-bar-plot",
    "href": "content/01_journal/01_tidyverse.html#analyse-sales-by-state-with-bar-plot",
    "title": "Tidyverse",
    "section": "2.1 Analyse sales by state with bar plot",
    "text": "2.1 Analyse sales by state with bar plot\n\nSplit column of location\nWith eval: true\n\nlocation_splitted = separate(\n    bike_orderlines_wrangled_tbl,\n    col = location,\n    into = c(\"city\", \"state\"),\n    sep = \",\")\n\nlocation_splitted\n\n\n\n  \n\n\n\n\n\nCalculate sales, group by state\n\nsales_by_state_tbl = location_splitted %&gt;%\n    dplyr::select(state, total_price) %&gt;%\n    mutate(state_1 = state) %&gt;%\n    group_by(state_1) %&gt;% \n    summarize(sales = sum(total_price)) %&gt;%\n    mutate(sales_text = scales::dollar(sales,\n                                      big.mark = \".\",\n                                      decimal.mark = \",\",\n                                      prefix = \"\",\n                                      suffix = \"€\"))\n\nsales_by_state_tbl\n\n\n\n  \n\n\n\n\n\nPlot bar\n\nsales_by_state_tbl %&gt;%\n    ggplot(aes(x = state_1, y = sales)) +\n    geom_col(fill = \"#2DC6D6\") + \n    geom_label(aes(label = sales_text)) +\n    scale_y_continuous(labels = scales::dollar_format(big.mark = \".\",\n                                                     decimal.mark = \",\",\n                                                     prefix = \"\",\n                                                     suffix = \"€\")) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n\n    labs(\n        title = \"Revenue by State\",\n        subtitle = \"\",\n        x = \"state\",\n        y = \"Revenue\"\n    )"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#analyse-sales-by-state-and-year-with-bar-plot",
    "href": "content/01_journal/01_tidyverse.html#analyse-sales-by-state-and-year-with-bar-plot",
    "title": "Tidyverse",
    "section": "2.2 Analyse sales by state and year with bar plot",
    "text": "2.2 Analyse sales by state and year with bar plot\n\ncalculate sales and group by state and year\n\nsales_by_state_year_tbl = location_splitted %&gt;%\n    dplyr::select(order_date, state, total_price) %&gt;%\n    mutate(year_1 = year(order_date)) %&gt;%\n    group_by(state, year_1) %&gt;% \n    summarize(sales = sum(total_price)) %&gt;%\n    mutate(sales_text = scales::dollar(sales,\n                                      big.mark = \".\",\n                                      decimal.mark = \",\",\n                                      prefix = \"\",\n                                      suffix = \"€\"))\n\n#&gt; `summarise()` has grouped output by 'state'. You can override using the\n#&gt; `.groups` argument.\n\nsales_by_state_year_tbl\n\n\n\n  \n\n\n\n\n\nPlot bar of all each states\n\nsales_by_state_year_tbl %&gt;% \n    ggplot(aes(x = year_1, y = sales, fill = state)) +\n    geom_col() +\n    facet_wrap(~ state) +\n    scale_y_continuous(labels = scales::dollar_format(big.mark = \".\",\n                                                     decimal.mark = \",\",\n                                                     prefix = \"\",\n                                                     suffix = \"€\")) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n\n    labs(\n        title = \"Revenue by year and state\",\n        subtitle = \"\",\n        fill = \"States\"\n    )"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Note\n\n\n\nMost of my notes of studying this chapter is done in ‘r-data-acquisition.ipynb’ (see workspace content). Just in case it is necessary to show it."
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#libraries",
    "href": "content/01_journal/02_data_acquisition.html#libraries",
    "title": "Data Acquisition",
    "section": "1.1 Libraries",
    "text": "1.1 Libraries\nJust simply get every library\n\nlibrary(readxl)\nlibrary(lubridate)\n\n#&gt; \n#&gt; Attache Paket: 'lubridate'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:base':\n#&gt; \n#&gt;     date, intersect, setdiff, union\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n#&gt; ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n#&gt; ✔ tibble  3.1.6     ✔ dplyr   1.0.8\n#&gt; ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#&gt; ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ lubridate::as.difftime() masks base::as.difftime()\n#&gt; ✖ lubridate::date()        masks base::date()\n#&gt; ✖ dplyr::filter()          masks stats::filter()\n#&gt; ✖ lubridate::intersect()   masks base::intersect()\n#&gt; ✖ dplyr::lag()             masks stats::lag()\n#&gt; ✖ lubridate::setdiff()     masks base::setdiff()\n#&gt; ✖ lubridate::union()       masks base::union()\n\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(RSQLite)\n\n#&gt; Warning: Paket 'RSQLite' wurde unter R Version 4.2.3 erstellt\n\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n#&gt; \n#&gt; Attache Paket: 'rvest'\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:readr':\n#&gt; \n#&gt;     guess_encoding\n\nlibrary(xopen)     # Quickly opening URLs\n\n#&gt; Warning: Paket 'xopen' wurde unter R Version 4.2.3 erstellt\n\nlibrary(jsonlite)  # converts JSON files to R objects\n\n#&gt; \n#&gt; Attache Paket: 'jsonlite'\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:purrr':\n#&gt; \n#&gt;     flatten\n\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\nlibrary(httr)\nlibrary(stringr)"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#get-a-free-api",
    "href": "content/01_journal/02_data_acquisition.html#get-a-free-api",
    "title": "Data Acquisition",
    "section": "2.1 Get a free API",
    "text": "2.1 Get a free API\n\napi_url = \"http://universities.hipolabs.com/search?country=germany\""
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#import-data",
    "href": "content/01_journal/02_data_acquisition.html#import-data",
    "title": "Data Acquisition",
    "section": "2.2 Import data",
    "text": "2.2 Import data\n\nresponse = GET(api_url)\ndata = content(response, as = \"text\")\n\n#&gt; No encoding supplied: defaulting to UTF-8.\n\ndata_list = fromJSON(data)"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#examine",
    "href": "content/01_journal/02_data_acquisition.html#examine",
    "title": "Data Acquisition",
    "section": "2.3 Examine",
    "text": "2.3 Examine\n\ntibble(data_list)"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#cleaning-data",
    "href": "content/01_journal/02_data_acquisition.html#cleaning-data",
    "title": "Data Acquisition",
    "section": "2.4 Cleaning Data",
    "text": "2.4 Cleaning Data\n\nChange every “-” to “_”\n\ncleaner_data_list = tibble(data_list) %&gt;% \n    dplyr::select(everything()) %&gt;%\n    set_names(names(.) %&gt;% str_replace_all(\"\\\\-\", \"_\")) %&gt;% \n    dplyr::mutate(name = gsub(\"-\", \" \", name))\n\n\n\nSee result\n\ncleaner_data_list\n\n\n\n  \n\n\n\n\n\nDelete unecesarry columns and reduce row to 20, because there is too much, then see result\n\nsmaller_cleaner_data_list = head(cleaner_data_list, n= 20) %&gt;% \n    dplyr::select(-(alpha_two_code), -(state_province))\n\nsmaller_cleaner_data_list\n\n\n\n  \n\n\n\n\n\nCount the number of words in the name column\n\n#word_counts &lt;- str_count(data_list$name, \"\\\\S+\")\n#word_counts = sapply(data_list$name, function(name) length(strsplit(name, \"[\\\\s-]+\")[[1]]))\n\nword_counts = sapply(smaller_cleaner_data_list$name, function(name) str_count(name, \"\\\\S+\"))\n\n\n\nInsert result into table\n\nsmaller_cleaner_data_list$simple_name = word_counts\n\n\n\nSee current result\n\ntibble(smaller_cleaner_data_list)"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#plot-readable-table",
    "href": "content/01_journal/02_data_acquisition.html#plot-readable-table",
    "title": "Data Acquisition",
    "section": "2.5 Plot readable table",
    "text": "2.5 Plot readable table\n\nsimplicity_of_name = smaller_cleaner_data_list %&gt;%\n    dplyr::select(name, simple_name)\n\nkable(simplicity_of_name)\n\n\n\n\n\n\n\n\nname\nsimple_name\n\n\n\n\nAKAD Hochschulen für Berufstätige, Fachhochschule Leipzig\n6\n\n\nHochschule für Berufstätige Rendsburg\n4\n\n\nAlice Salomon Fachhochschule für Sozialarbeit und Sozialpädagogik Berlin\n8\n\n\nAugustana Hochschule Neuendettelsau\n3\n\n\nKirchliche Hochschule Bethel\n3\n\n\nBiTS Business and Information Technology School gGmbH\n7\n\n\nCologne Business School\n3\n\n\nCODE University of Applied Sciences Berlin\n6\n\n\nDeutsche Hochschule für Verwaltungswissenschaften Speyer\n5\n\n\nDIPLOMA Fachhochschule Ölsnitz/Vogtland\n3\n\n\nFachhochschule Nordhessen\n2\n\n\nDeutsche Sporthochschule Köln\n3\n\n\nE.A.P. Europäische Wirtschaftshochschule Berlin\n4\n\n\nEuropäische Betriebswirtschafts Akademie\n3\n\n\nEuropean Business School Schloß Reichartshausen\n5\n\n\nEuropean College of Liberal Arts\n5\n\n\nEvangelische Fachhochschule Rheinland Westfalen Lippe\n5\n\n\nEvangelische Fachhochschule Darmstadt\n3\n\n\nEvangelische Fachhochschule Freiburg, Hochschule für Soziale Arbeit, Diakonie und Religionspädagogik\n10\n\n\nEvangelische Fachhochschule Hannover\n3\n\n\n\n\n\n\ndev.new(width = 750, height = 530, unit = \"px\")\nplot(1:15)"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#plot-graph",
    "href": "content/01_journal/02_data_acquisition.html#plot-graph",
    "title": "Data Acquisition",
    "section": "2.6 Plot graph",
    "text": "2.6 Plot graph\n\n\n\n\n\n\nNote\n\n\n\nThe graph plotting works fine in other notebook platforms, but in RStudio it seems very squished. Therefore the original image is attached below after the code’s plot.\n\n\n\nsimplicity_of_name %&gt;%\n\n    # Setup canvas with the columns year (x-axis) and sales (y-axis)\n    ggplot(aes(x = name, y = simple_name)) +\n\n    # Geometries\n    geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n    geom_label(aes(label = simple_name)) + # Adding labels to the bars\n\n    # Formatting\n    # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. \n    # Again, we have to adjust it for euro values\n    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +\n\n    labs(\n        title    = \"Simplicity of university names\",\n        subtitle = \"Less is simpler\",\n        x = \"\", # Override defaults for x and y\n        y = \"Complexity of names\"\n    )\n\n\n\n\n\n\n\n\n\n\n\nOriginal plot"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Note\n\n\n\nMost of my notes of studying this chapter is done in ‘r-data-wrangling.ipynb’ (see workspace content). Just in case it is necessary to show it."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#libraries",
    "href": "content/01_journal/03_data_wrangling.html#libraries",
    "title": "Data Wrangling",
    "section": "1.1 Libraries",
    "text": "1.1 Libraries\nJust simply get every library\n\nlibrary(readxl)\nlibrary(lubridate)\n\n#&gt; \n#&gt; Attache Paket: 'lubridate'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:base':\n#&gt; \n#&gt;     date, intersect, setdiff, union\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n#&gt; ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n#&gt; ✔ tibble  3.1.6     ✔ dplyr   1.0.8\n#&gt; ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#&gt; ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ lubridate::as.difftime() masks base::as.difftime()\n#&gt; ✖ lubridate::date()        masks base::date()\n#&gt; ✖ dplyr::filter()          masks stats::filter()\n#&gt; ✖ lubridate::intersect()   masks base::intersect()\n#&gt; ✖ dplyr::lag()             masks stats::lag()\n#&gt; ✖ lubridate::setdiff()     masks base::setdiff()\n#&gt; ✖ lubridate::union()       masks base::union()\n\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(RSQLite)\n\n#&gt; Warning: Paket 'RSQLite' wurde unter R Version 4.2.3 erstellt\n\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n#&gt; \n#&gt; Attache Paket: 'rvest'\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:readr':\n#&gt; \n#&gt;     guess_encoding\n\nlibrary(xopen)     # Quickly opening URLs\n\n#&gt; Warning: Paket 'xopen' wurde unter R Version 4.2.3 erstellt\n\nlibrary(jsonlite)  # converts JSON files to R objects\n\n#&gt; \n#&gt; Attache Paket: 'jsonlite'\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:purrr':\n#&gt; \n#&gt;     flatten\n\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\nlibrary(httr)\nlibrary(stringr)\nlibrary(data.table)\n\n#&gt; \n#&gt; Attache Paket: 'data.table'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:dplyr':\n#&gt; \n#&gt;     between, first, last\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:purrr':\n#&gt; \n#&gt;     transpose\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:lubridate':\n#&gt; \n#&gt;     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#&gt;     yday, year\n\nlibrary(vroom)"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#data-import",
    "href": "content/01_journal/03_data_wrangling.html#data-import",
    "title": "Data Wrangling",
    "section": "2.1 Data import",
    "text": "2.1 Data import\n\nimport from patent.tsv\n\nCreating a table, and then importing from .tsv into the table.\n\\ t is for tab-delimited files (.tsv). Seperating columns by their tabbed white spaces. (Import to excel to clearly see it)\nskip = 1 the first row, becuase they are just titles\ncommon column values’s name are made the same, to match the data variables (eg: id)\n\n\ncol_types &lt;- list(\n  id = col_character(),\n    date = col_date(\"%Y-%m-%d\"),\n    num_claims = col_double(),\n  type = col_character(),\n  number = col_character(),\n  country = col_character(),\n  \n  abstract = col_character(),\n  title = col_character(),\n  kind = col_character(),\n  \n  filename = col_character(),\n  withdrawn = col_double()\n)\n\npatent_tbl &lt;- vroom(\n            file       = \"Patent_data_reduced/Patent_data_reduced/patent.tsv\", \n            skip = 1,\n            delim      = \"\\t\", \n            col_names  = names(col_types),\n            col_types  = col_types,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\n\n\nimport from patent_assignee.tsv\n\ncol_types_patent_assignee &lt;- list(\n  id = col_character(),\n  assignee = col_character()\n)\n\npatent_assignee_tbl &lt;- vroom(\n            file       = \"Patent_data_reduced/Patent_data_reduced/patent_assignee.tsv\", \n            skip = 1,\n            delim      = \"\\t\", \n            col_names  = names(col_types_patent_assignee),\n            col_types  = col_types_patent_assignee,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\n\n\nimport from assignee.tsv\n\ncol_types_assignee &lt;- list(\n  assignee = col_character(),\n    type = col_character(),\n    organization = col_character()\n)\n\nassignee_tbl &lt;- vroom(\n            file       = \"Patent_data_reduced/Patent_data_reduced/assignee.tsv\", \n            skip = 1,\n            delim      = \"\\t\", \n            col_names  = names(col_types_assignee),\n            col_types  = col_types_assignee,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )\n\n\n\nimport from uspc.tsv\n\ncol_types_uspc &lt;- list(\n  id = col_character(),\n    mainclass_id = col_character(),\n    sequence = col_double()\n)\n\nuspc_tbl &lt;- vroom(\n            file       = \"Patent_data_reduced/Patent_data_reduced/uspc.tsv\", \n            skip = 1,\n            delim      = \"\\t\", \n            col_names  = names(col_types_uspc),\n            col_types  = col_types_uspc,\n            na         = c(\"\", \"NA\", \"NULL\")\n        )"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#see-results",
    "href": "content/01_journal/03_data_wrangling.html#see-results",
    "title": "Data Wrangling",
    "section": "2.2 See results",
    "text": "2.2 See results\n\npatent_tbl\n\n\n\n  \n\n\npatent_assignee_tbl\n\n\n\n  \n\n\nassignee_tbl\n\n\n\n  \n\n\nuspc_tbl"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#convert-to-data.table",
    "href": "content/01_journal/03_data_wrangling.html#convert-to-data.table",
    "title": "Data Wrangling",
    "section": "2.3 Convert to data.table",
    "text": "2.3 Convert to data.table\n\n# patent Data ----\nsetDT(patent_tbl)\n\nclass(patent_tbl)\n\n#&gt; [1] \"data.table\" \"data.frame\"\n\npatent_tbl %&gt;% glimpse()\n\n#&gt; Rows: 327,014\n#&gt; Columns: 3\n#&gt; $ id         &lt;chr&gt; \"8621662\", \"8621663\", \"8621664\", \"8621665\", \"8621666\", \"862…\n#&gt; $ date       &lt;date&gt; 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-07…\n#&gt; $ num_claims &lt;dbl&gt; 11, 6, 10, 18, 7, 9, 21, 19, 8, 18, 7, 15, 15, 15, 18, 7, 1…\n\n# patent-assignee Data ----\nsetDT(patent_assignee_tbl)\n\npatent_assignee_tbl %&gt;% glimpse()\n\n#&gt; Rows: 315,910\n#&gt; Columns: 2\n#&gt; $ id       &lt;chr&gt; \"8709412\", \"8636251\", \"8899346\", \"8700141\", \"8724986\", \"D6998…\n#&gt; $ assignee &lt;chr&gt; \"org_MPhnVOTFsXybN0auC647\", \"org_v7VisXnmZZEEUMeHhW6y\", \"org_…\n\n# assignee Data ----\nsetDT(assignee_tbl)\nassignee_tbl %&gt;% glimpse()\n\n#&gt; Rows: 47,011\n#&gt; Columns: 3\n#&gt; $ assignee     &lt;chr&gt; \"org_004j997jM9yEdS7z4ReD\", \"org_005hVGA5JMOZsS0xOhGa\", \"…\n#&gt; $ type         &lt;chr&gt; \"3\", \"3\", \"2\", \"2\", \"3\", \"3\", \"2\", \"3\", \"2\", \"3\", \"2\", \"2…\n#&gt; $ organization &lt;chr&gt; \"University of Basel\", \"Zetkama Spólka Akcyjna\", \"Mirabil…\n\n# uspc Data\nsetDT(uspc_tbl)\nuspc_tbl %&gt;% glimpse()\n\n#&gt; Rows: 815,743\n#&gt; Columns: 3\n#&gt; $ id           &lt;chr&gt; \"8829273\", \"8623780\", \"8904894\", \"8794165\", \"8773920\", \"8…\n#&gt; $ mainclass_id &lt;chr&gt; \"435\", \"502\", \"368\", \"111\", \"365\", \"128\", \"709\", \"707\", \"…\n#&gt; $ sequence     &lt;dbl&gt; 7, 2, 0, 1, 0, 4, 2, 1, 2, 2, 10, 1, 2, 4, 1, 1, 9, 0, 2,…"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#data-wrangling",
    "href": "content/01_journal/03_data_wrangling.html#data-wrangling",
    "title": "Data Wrangling",
    "section": "2.4 Data wrangling",
    "text": "2.4 Data wrangling\n\ncombine by id\nall.x = TRUE: all rows included\nall.y = FALSE: only mathcing rows will be combined to x\nuspc has the most id rows\npatent has the 2nd most id rows\npatent-assignee 3rd\nassignee 4th least rows\n\n\ncombined_data_patent_1 &lt;- merge(x = uspc_tbl, y = patent_tbl, \n                       by    = \"id\", \n                       all.x = TRUE, \n                       all.y = FALSE)\n\n\ncombined_data_patent_1 %&gt;% glimpse()\n\n#&gt; Rows: 815,743\n#&gt; Columns: 5\n#&gt; $ id           &lt;chr&gt; \"8621662\", \"8621663\", \"8621663\", \"8621664\", \"8621664\", \"8…\n#&gt; $ mainclass_id &lt;chr&gt; \"2\", \"2\", \"351\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", …\n#&gt; $ sequence     &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 3, 2, 4, 0, 2, 1, 3, 0, …\n#&gt; $ date         &lt;date&gt; 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-…\n#&gt; $ num_claims   &lt;dbl&gt; 11, 6, 6, 10, 10, 18, 7, 7, 9, 21, 21, 21, 21, 21, 19, 19…\n\n\n\ncombined_data_patent_2 &lt;- merge(x = combined_data_patent_1, y = patent_assignee_tbl, \n                       by    = \"id\", \n                       all.x = TRUE, \n                       all.y = FALSE)\n\n\ncombined_data_patent_2 %&gt;% glimpse()\n\n#&gt; Rows: 848,347\n#&gt; Columns: 6\n#&gt; $ id           &lt;chr&gt; \"8621662\", \"8621663\", \"8621663\", \"8621664\", \"8621664\", \"8…\n#&gt; $ mainclass_id &lt;chr&gt; \"2\", \"2\", \"351\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", …\n#&gt; $ sequence     &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 3, 2, 4, 0, 2, 1, 3, 0, …\n#&gt; $ date         &lt;date&gt; 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-…\n#&gt; $ num_claims   &lt;dbl&gt; 11, 6, 6, 10, 10, 18, 7, 7, 9, 21, 21, 21, 21, 21, 19, 19…\n#&gt; $ assignee     &lt;chr&gt; \"org_aTMUEAbUvQuADfnSfudQ\", \"org_FfZ2sonhh4RvKY8vYp2B\", \"…\n\n\n\ncombined_data_patent_3 &lt;- merge(x = combined_data_patent_2, y = assignee_tbl, \n                       by    = \"assignee\", \n                       all.x = TRUE, \n                       all.y = FALSE)\n\n\ncombined_data_patent_3 %&gt;% glimpse()\n\n#&gt; Rows: 848,347\n#&gt; Columns: 8\n#&gt; $ assignee     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n#&gt; $ id           &lt;chr&gt; \"8621664\", \"8621664\", \"8621665\", \"8621667\", \"8621672\", \"8…\n#&gt; $ mainclass_id &lt;chr&gt; \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2\", \"15\", \"…\n#&gt; $ sequence     &lt;dbl&gt; 0, 1, 0, 0, 0, 4, 1, 3, 2, 0, 0, 2, 1, 0, 1, 0, 1, 0, 2, …\n#&gt; $ date         &lt;date&gt; 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-07, 2014-01-…\n#&gt; $ num_claims   &lt;dbl&gt; 10, 10, 18, 9, 7, 15, 15, 15, 15, 15, 1, 19, 19, 19, 18, …\n#&gt; $ type         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n#&gt; $ organization &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#data-filtering",
    "href": "content/01_journal/03_data_wrangling.html#data-filtering",
    "title": "Data Wrangling",
    "section": "2.5 Data filtering",
    "text": "2.5 Data filtering\n\nPicking only the US companies using grepl()\n“Inc.” (Incorporated), “Corp.” (Corporation), “LLC” (Limited Liability Company), or “Co.” (Company).\nignoring “Co., Ltd.”, because those are typical eastern asian companies\nOR Use type = 2, it means US companies\n\n\n#US_combined_data_patent &lt;- combined_data_patent_3[grepl(\"Inc\\\\.|Corp\\\\.|LLC|Co\\\\.\", organization) & !grepl(\"Co\\\\., Ltd\\\\.\", organization)] \nUS_combined_data_patent &lt;- combined_data_patent_3[grepl(2, type)]"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#calculation",
    "href": "content/01_journal/03_data_wrangling.html#calculation",
    "title": "Data Wrangling",
    "section": "2.6 Calculation",
    "text": "2.6 Calculation\n\nCount how many times a name appeared, to see how many patents they each have. And reorder row.\n\n\nnumber_of_patents_owned &lt;- US_combined_data_patent[, .N, by = organization]\nsetnames(number_of_patents_owned, \"N\", \"number_of_patents_owned\")\n\nnumber_of_patents_owned\n\n\n\n  \n\n\n#setorderv(number_of_patents_owned, c(\"number_of_patents_owned\", \"organization\"))\n#setorderv(number_of_patents_owned, -(number_of_patents_owned))\nUS_combined_data_patent_descending = number_of_patents_owned %&gt;% arrange(desc(number_of_patents_owned))"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#plot-readable-table",
    "href": "content/01_journal/03_data_wrangling.html#plot-readable-table",
    "title": "Data Wrangling",
    "section": "2.7 Plot readable table",
    "text": "2.7 Plot readable table\n\nkable(head(US_combined_data_patent_descending, n = 10))\n\n\n\n\norganization\nnumber_of_patents_owned\n\n\n\n\nInternational Business Machines Corporation\n19056\n\n\nQUALCOMM Incorporated\n7322\n\n\nMicrosoft Corporation\n7195\n\n\nGoogle Inc.\n6082\n\n\nApple Inc.\n5542\n\n\nAT&T INTELLECTUAL PROPERTY I, L.P.\n5010\n\n\nGeneral Electric Company\n4646\n\n\nIntel Corporation\n4252\n\n\nGM Global Technology Operations LLC\n3920\n\n\nBroadcom Corporation\n3736"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#picking-out-only-aug-2014",
    "href": "content/01_journal/03_data_wrangling.html#picking-out-only-aug-2014",
    "title": "Data Wrangling",
    "section": "3.1 Picking out only Aug 2014",
    "text": "3.1 Picking out only Aug 2014\n\n#month = month(date)\nUS_combined_data_patent_Aug_2014 = US_combined_data_patent[format(date, \"%Y-%m\") %like% \"2014-08\"]\nUS_combined_data_patent_Aug_2014"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#calculation-1",
    "href": "content/01_journal/03_data_wrangling.html#calculation-1",
    "title": "Data Wrangling",
    "section": "3.2 Calculation",
    "text": "3.2 Calculation\n\nCount how many times a name appeared, to see how many patents they each have. And reorder row\n\n\nnumber_of_patents_owned_aug_2014 &lt;- US_combined_data_patent_Aug_2014[, .N, by = organization]\nsetnames(number_of_patents_owned_aug_2014, \"N\", \"number_of_patents_owned_aug_2014\")\n\nnumber_of_patents_owned_aug_2014\n\n\n\n  \n\n\n#setorderv(number_of_patents_owned, c(\"number_of_patents_owned\", \"organization\"))\n#setorderv(number_of_patents_owned, -(number_of_patents_owned))\nUS_combined_data_patent_descending_aug_2014 = number_of_patents_owned_aug_2014 %&gt;% arrange(desc(number_of_patents_owned_aug_2014))"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#plot-readable-table-1",
    "href": "content/01_journal/03_data_wrangling.html#plot-readable-table-1",
    "title": "Data Wrangling",
    "section": "3.3 Plot readable table",
    "text": "3.3 Plot readable table\n\nkable(head(US_combined_data_patent_descending_aug_2014, n = 10))\n\n\n\n\n\n\n\n\norganization\nnumber_of_patents_owned_aug_2014\n\n\n\n\nInternational Business Machines Corporation\n1810\n\n\nMicrosoft Corporation\n779\n\n\nQUALCOMM Incorporated\n591\n\n\nGoogle Inc.\n566\n\n\nApple Inc.\n501\n\n\nIntel Corporation\n404\n\n\nAT&T INTELLECTUAL PROPERTY I, L.P.\n401\n\n\nBroadcom Corporation\n353\n\n\nGeneral Electric Company\n345\n\n\nHewlett-Packard Development Company, L.P.\n341"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#top-10-companies-worldwide",
    "href": "content/01_journal/03_data_wrangling.html#top-10-companies-worldwide",
    "title": "Data Wrangling",
    "section": "4.1 Top 10 companies worldwide",
    "text": "4.1 Top 10 companies worldwide\n\nGet data with above 300 mainclass_id\n\n#combined_data_patent_tech &lt;- combined_data_patent_3[grepl(&gt;300, mainclass_id)]\n\n#above_300 = combined_data_patent_3$mainclass_id &gt; 300\n\n#mainclass_id_num = as.numeric(combined_data_patent_3$mainclass_id)\nabove_300 = 300\n\ncombined_data_patent_tech = combined_data_patent_3[grepl(\"^\\\\d+$\", mainclass_id) & as.numeric(mainclass_id) &gt; above_300]\n\n#&gt; Warning in eval(.massagei(isub), x, ienv): NAs durch Umwandlung erzeugt\n\ncombined_data_patent_tech\n\n\n\n  \n\n\n\n\n\nCalculation\n\nCount how many times a name appeared, to see how many patents they each have. And reorder row\n\n\nnumber_of_patents_owned_tech_worldwide &lt;- combined_data_patent_tech[, .N, by = organization]\nsetnames(number_of_patents_owned_tech_worldwide, \"N\", \"number_of_patents_owned_tech_worldwide\")\n\nnumber_of_patents_owned_tech_worldwide = number_of_patents_owned_tech_worldwide[organization != \"NA\"]\nnumber_of_patents_owned_tech_worldwide\n\n\n\n  \n\n\n#setorderv(number_of_patents_owned, c(\"number_of_patents_owned\", \"organization\"))\n#setorderv(number_of_patents_owned, -(number_of_patents_owned))\nnumber_of_patents_owned_tech_worldwide_descending = number_of_patents_owned_tech_worldwide %&gt;% arrange(desc(number_of_patents_owned_tech_worldwide))\n\n\n\nPlot readable table\n\nkable(head(number_of_patents_owned_tech_worldwide_descending, n = 10))\n\n\n\n\n\n\n\n\norganization\nnumber_of_patents_owned_tech_worldwide\n\n\n\n\nInternational Business Machines Corporation\n15948\n\n\nSamsung Electronics Co., Ltd.\n11469\n\n\nCanon Kabushiki Kaisha\n8291\n\n\nSony Corporation\n7403\n\n\nQUALCOMM Incorporated\n7098\n\n\nMicrosoft Corporation\n7077\n\n\nGoogle Inc.\n5908\n\n\nApple Inc.\n5125\n\n\nAT&T INTELLECTUAL PROPERTY I, L.P.\n4985\n\n\nLG Electronics Inc.\n4854"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#top-5-uspto-tech-main-classes",
    "href": "content/01_journal/03_data_wrangling.html#top-5-uspto-tech-main-classes",
    "title": "Data Wrangling",
    "section": "4.2 Top 5 USPTO tech main classes",
    "text": "4.2 Top 5 USPTO tech main classes\n\nUS_combined_data_patent_tech = combined_data_patent_tech[grepl(2, type)]\nUS_combined_data_patent_tech\n\n\n\n  \n\n\n\n\nOrganizing\n\nTop_USPTO = US_combined_data_patent_tech %&gt;% arrange(desc(sequence))\n\n\nTop_USPTO_1 = Top_USPTO[, organization := as.character(organization)]\nTop_USPTO_2 = Top_USPTO[, .(sequence = max(sequence)), by = organization]\nTop_USPTO_2\n\n\n\n  \n\n\n\n\n\nPlot readable table\n\nkable(head(Top_USPTO_2, n = 5))\n\n\n\n\norganization\nsequence\n\n\n\n\nAT&T INTELLECTUAL PROPERTY I, L.P.\n77\n\n\nApple Inc.\n62\n\n\nAlverix, Inc.\n61\n\n\nSONY NETWORK ENTERTAINMENT INTERNATIONAL LLC\n60\n\n\nSony Electronics Inc.\n58"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Note\n\n\n\nMost of my notes of studying this chapter is done in ‘r-data-visualization.ipynb’ (see workspace content). Just in case it is necessary to show it."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#libraries",
    "href": "content/01_journal/04_data_visualization.html#libraries",
    "title": "Data Visualization",
    "section": "1.1 Libraries",
    "text": "1.1 Libraries\nJust simply get every library\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n#&gt; ✔ ggplot2 3.3.5     ✔ purrr   0.3.4\n#&gt; ✔ tibble  3.1.6     ✔ dplyr   1.0.8\n#&gt; ✔ tidyr   1.2.0     ✔ stringr 1.4.0\n#&gt; ✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n#&gt; \n#&gt; Attache Paket: 'lubridate'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:base':\n#&gt; \n#&gt;     date, intersect, setdiff, union\n\nlibrary(readxl)\nlibrary(knitr)\nlibrary(RSQLite)\n\n#&gt; Warning: Paket 'RSQLite' wurde unter R Version 4.2.3 erstellt\n\nlibrary(data.table)\n\n#&gt; \n#&gt; Attache Paket: 'data.table'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:lubridate':\n#&gt; \n#&gt;     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n#&gt;     yday, year\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:dplyr':\n#&gt; \n#&gt;     between, first, last\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:purrr':\n#&gt; \n#&gt;     transpose\n\nlibrary(scales)\n\n#&gt; \n#&gt; Attache Paket: 'scales'\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:purrr':\n#&gt; \n#&gt;     discard\n\n\n#&gt; Das folgende Objekt ist maskiert 'package:readr':\n#&gt; \n#&gt;     col_factor\n\nlibrary(ggrepel)"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#import-data",
    "href": "content/01_journal/04_data_visualization.html#import-data",
    "title": "Data Visualization",
    "section": "1.2 IMport data",
    "text": "1.2 IMport data\n\nlibrary(tidyverse)\ncovid_data_tbl &lt;- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#&gt; Rows: 313070 Columns: 67\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr   (4): iso_code, continent, location, tests_units\n#&gt; dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#&gt; date  (1): date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#data-manipulation",
    "href": "content/01_journal/04_data_visualization.html#data-manipulation",
    "title": "Data Visualization",
    "section": "2.1 Data Manipulation",
    "text": "2.1 Data Manipulation\n\ncovid_data_dt = data.table(covid_data_tbl)\nclass(covid_data_dt)\n\n#&gt; [1] \"data.table\" \"data.frame\"\n\n#covid_data_dt\n\n\nConvert date to tb\n\ncovid_data_dt[, date := as.Date(date)]\n\n\n\nextract year and month\n\ncovid_data_dt[, year_month := format(date, \"%Y-%m\")]\n\n\n\nsee result, and calculate total new cases for each month\n\ncovid_data_new_cases_per_month_dt = covid_data_dt[!is.na(new_cases), .(new_cases_per_month = sum(new_cases)), by = .(year_month, location)]\ncovid_data_new_cases_per_month_dt\n\n\n\n  \n\n\n\n\n\nfilter locations\n\nchosen_locations = c(\"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\")\n\ncovid_data_new_cases_per_month_per_chosen_locations_dt = covid_data_new_cases_per_month_dt[location %in% chosen_locations]\n\n#covid_data_new_cases_per_month_per_chosen_locations_dt \ncovid_data_new_cases_per_month_per_chosen_locations_dt %&gt;% glimpse()\n\n#&gt; Rows: 205\n#&gt; Columns: 3\n#&gt; $ year_month          &lt;chr&gt; \"2020-01\", \"2020-02\", \"2020-03\", \"2020-04\", \"2020-…\n#&gt; $ location            &lt;chr&gt; \"France\", \"France\", \"France\", \"France\", \"France\", …\n#&gt; $ new_cases_per_month &lt;dbl&gt; 6, 51, 43920, 83089, 21170, 11138, 20620, 111684, …\n\n\n\n\ncumulative calculation\n\n#covid_data_new_cases_per_month_per_chosen_locations_dt[, year_month := as.Date(year_month, format = \"%Y-%m\")]\ncovid_data_new_cases_per_month_per_chosen_locations_dt[, year_month := as.character(year_month)]\ncovid_data_new_cases_per_month_per_chosen_locations_dt[, cumulative_cases := cumsum(new_cases_per_month), by = .(location)]\n\n\n\nGet final cumulative number\n\nlast_value = covid_data_new_cases_per_month_per_chosen_locations_dt %&gt;%\n  group_by(location) %&gt;%\n  filter(year_month == max(year_month)) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#plot-line-graph",
    "href": "content/01_journal/04_data_visualization.html#plot-line-graph",
    "title": "Data Visualization",
    "section": "2.2 Plot line graph",
    "text": "2.2 Plot line graph\n\nggplot(covid_data_new_cases_per_month_per_chosen_locations_dt, aes(x = year_month, y = cumulative_cases, color = location, group = location)) +\n  geom_line() +\n\n#geom_text(data = last_value, aes(label = cumulative_cases), hjust = 1, vjust = 1, color = \"blue\")+\ngeom_label_repel(data = last_value, aes(label = cumulative_cases), show.legend = TRUE, nudge_x = 0.01, nudge_y = 5000000, direction = \"y\") +\ntheme_dark() +\n#theme_minimal() +\n  #scale_x_date(date_labels = \"%Y-%m\", date_breaks = \"1 month\") +\ntheme(axis.text.x = element_text(angle = 45, hjust = 1, color = \"black\"),\n        plot.title = element_text(face = \"bold\", color = \"black\"),\n        plot.caption = element_text(face = \"bold.italic\", color = \"black\"),\n        legend.position = \"bottom\",\n     legend.text = element_text(color = \"black\"),\n     legend.title = element_text(color = \"black\")) +\n#theme_minimal() +\n\n  labs(\n    title = \"Covid 19 confirm cases worldwdie\",\n    subtitle = \"As of 19.04.2022\",\n    x = \"Date\",\n    y = \"Cumulative Cases\",\n    color = \"Country\"\n      #show.legend = TRUE\n  ) +\n    scale_y_continuous(labels = function(x) paste0(x / 500000, \"M\"))"
  },
  {
    "objectID": "content/01_journal/Test_Training.html",
    "href": "content/01_journal/Test_Training.html",
    "title": "Test page",
    "section": "",
    "text": "Note\n\n\n\nNotes go here ödnajkwdnöjanjlnald\nWith eval: false\nnumbers &lt;- 1:1000\n\n# This will print the first 10 elements of the vector numbers\nnumbers[1:10]\n\n# This will plot a histogram of 100 random elements of the vector numbers\nhist(sample(numbers, 100, replace = T))\nrandom calculate and print\na=5\nb=4\nc=a+b\nprint(paste0(c))\n\n#&gt; [1] \"9\"\nwith eval: true\nnumbers &lt;- 1:1000\n\n# This will print the first 10 elements of the vector numbers\nnumbers[1:10]\n\n#&gt;  [1]  1  2  3  4  5  6  7  8  9 10\n\n# This will plot a histogram of 100 random elements of the vector numbers\nhist(sample(numbers, 100, replace = T))\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/Test_Training.html#header-2",
    "href": "content/01_journal/Test_Training.html#header-2",
    "title": "Test page",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  }
]